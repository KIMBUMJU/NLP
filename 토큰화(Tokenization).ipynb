{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "😊주어진 코퍼스(coupus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)\n",
        "\n",
        "😊즉, 문장을 문장 단위, 어절 단위, 형태소 단위로 나누는 것을 말하며 나누어진 토큰을 컴퓨터가 이해할 수 있게 정수로 매핑해야 함"
      ],
      "metadata": {
        "id": "MWnb_vhVnMks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gdyGx5yhnLi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 단어 토큰화(Word Tokenization)\n",
        "\n",
        "입력: My name is Bumju Kim.\n",
        "\n",
        "출력: \"My\", \"name\", \"is\", \"Bumju\", \"Kim\"\n",
        "\n",
        "**NLTK는 영어 코퍼스를 토큰화하기 위한 도구들을 제공: word_tokenize & WorkPunctTokenizer**"
      ],
      "metadata": {
        "id": "e7ORhpBVnM0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erj6LHz9qK2D",
        "outputId": "99f4de35-18ab-4421-81b9-f6fb90a16e4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVaCRRjsoRaH",
        "outputId": "8915b20a-0b24-497b-9a18-8cb087d746e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(\"From now on, don't think of any bad things. Mr. Kim's program will help us, ok?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNf7HHnApu7h",
        "outputId": "3aa9cc9a-8a6f-4358-b336-6a755f623a22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['From', 'now', 'on', ',', 'do', \"n't\", 'think', 'of', 'any', 'bad', 'things', '.', 'Mr.', 'Kim', \"'s\", 'program', 'will', 'help', 'us', ',', 'ok', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "print(WordPunctTokenizer().tokenize(\"From now on, don't think of any bad things. Mr. Kim's program will help us, ok?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj2hO9nuq9-8",
        "outputId": "86af1c37-ea28-4156-a604-96cc246d56b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['From', 'now', 'on', ',', 'don', \"'\", 't', 'think', 'of', 'any', 'bad', 'things', '.', 'Mr', '.', 'Kim', \"'\", 's', 'program', 'will', 'help', 'us', ',', 'ok', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 문장 토큰화(Sentence Tokenization)"
      ],
      "metadata": {
        "id": "O83oF2JDrwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Today is a day. We have to show everything that we prepared for this moment. But, don't forget, it will not easy. I believe you guys. Cheer up!\"\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItzNWpbJrL8d",
        "outputId": "af12880b-de9a-4b06-8ccd-bd30bfee004e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Today is a day.', 'We have to show everything that we prepared for this moment.', \"But, don't forget, it will not easy.\", 'I believe you guys.', 'Cheer up!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. NLTK 이용하여 영어 토큰화 및 품사 태깅"
      ],
      "metadata": {
        "id": "krDP35O-uWzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"From now on, don't think of any bad things. Mr. Kim's program will help us, ok?\"\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxvvwhotsUKV",
        "outputId": "fc5f307d-7eb2-4777-a101-9db2147fe95c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['From', 'now', 'on', ',', 'do', \"n't\", 'think', 'of', 'any', 'bad', 'things', '.', 'Mr.', 'Kim', \"'s\", 'program', 'will', 'help', 'us', ',', 'ok', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "p = word_tokenize(text)\n",
        "pos_tag(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw0mvCI2u8D5",
        "outputId": "9f44c56e-dc0c-4005-ff96-67ba84136ea7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('From', 'IN'),\n",
              " ('now', 'RB'),\n",
              " ('on', 'IN'),\n",
              " (',', ','),\n",
              " ('do', 'VBP'),\n",
              " (\"n't\", 'RB'),\n",
              " ('think', 'VB'),\n",
              " ('of', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('bad', 'JJ'),\n",
              " ('things', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Mr.', 'NNP'),\n",
              " ('Kim', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('program', 'NN'),\n",
              " ('will', 'MD'),\n",
              " ('help', 'VB'),\n",
              " ('us', 'PRP'),\n",
              " (',', ','),\n",
              " ('ok', 'PRP'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. KoNLPy를 이용하여 한국어 토큰화 및 품사 태깅\n",
        "\n",
        "⚙ KoNLPy: 파이썬 한국어 NLP: [https://konlpy.org/ko/latest/index.html](https://konlpy.org/ko/latest/index.html)\n",
        "\n",
        "⚙ 한글 형태소 분류기: Hananum, Kkma, Komoran, Mecab, Okt"
      ],
      "metadata": {
        "id": "pPYX-qcqZG8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSTHsCZOvLRz",
        "outputId": "feb11734-398f-494c-ef78-217861f5e120"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OKT 형태소 분석기"
      ],
      "metadata": {
        "id": "_msP5tu5afn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "Bzk4nbQOabby"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()"
      ],
      "metadata": {
        "id": "GbqPmlBZaqEY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# morphs: 형태소 추출\n",
        "print(okt.morphs(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnw2UdaQar2T",
        "outputId": "af41dfba-3101-4a19-bc0f-c77b2c71b0d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고생', '을', '한', '사람', '끝', '에', '낙', '이', '온다', '.', '사실', '더', '큰', '고통', ',', '시련', ',', '어둠', '이', '몰려온다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos: 품사 태깅(Part-of-Speech tagging)\n",
        "print(okt.pos(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJmgprBbAGi",
        "outputId": "74f9c866-46fc-4cbd-bf4e-c4219bb185f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('고생', 'Noun'), ('을', 'Josa'), ('한', 'Verb'), ('사람', 'Noun'), ('끝', 'Noun'), ('에', 'Josa'), ('낙', 'Noun'), ('이', 'Josa'), ('온다', 'Verb'), ('.', 'Punctuation'), ('사실', 'Noun'), ('더', 'Noun'), ('큰', 'Verb'), ('고통', 'Noun'), (',', 'Punctuation'), ('시련', 'Noun'), (',', 'Punctuation'), ('어둠', 'Noun'), ('이', 'Josa'), ('몰려온다', 'Verb'), ('.', 'Punctuation')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nouns: 명사 추출\n",
        "print(okt.nouns(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTHetAj7btLd",
        "outputId": "60aacd69-4abd-4639-d600-0aa1d3f686f1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고생', '사람', '끝', '낙', '사실', '더', '고통', '시련', '어둠']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 꼬꼬마 형태소 분석기(Kkma)"
      ],
      "metadata": {
        "id": "4a51ElJacthQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()"
      ],
      "metadata": {
        "id": "yd4ekMxRckoG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# morphs: 형태소 추출\n",
        "print(kkma.morphs(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uScapj0vc5_o",
        "outputId": "10429174-e59b-4901-8995-0268a05822d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고생', '을', '하', 'ㄴ', '사람', '끝', '에', '낙', '이', '오', 'ㄴ다', '.', '사실', '더', '크', 'ㄴ', '고통', ',', '시련', ',', '어둠', '이', '몰려오', 'ㄴ다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos: 품사 태깅(Part-of-speech tagging)\n",
        "print(kkma.pos(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnmAHh_0dWP_",
        "outputId": "1cae1a77-545f-4ac2-98c8-ec786c10ac18"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('고생', 'NNG'), ('을', 'JKO'), ('하', 'VV'), ('ㄴ', 'ETD'), ('사람', 'NNG'), ('끝', 'NNG'), ('에', 'JKM'), ('낙', 'NNG'), ('이', 'JKS'), ('오', 'VV'), ('ㄴ다', 'EFN'), ('.', 'SF'), ('사실', 'NNG'), ('더', 'MAG'), ('크', 'VA'), ('ㄴ', 'ETD'), ('고통', 'NNG'), (',', 'SP'), ('시련', 'NNG'), (',', 'SP'), ('어둠', 'NNG'), ('이', 'JKS'), ('몰려오', 'VV'), ('ㄴ다', 'EFN'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nouns: 명사 추출\n",
        "print(kkma.nouns(\"고생을 한 사람 끝에 낙이 온다. 사실 더 큰 고통, 시련, 어둠이 몰려온다.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6lD4pH_dn-V",
        "outputId": "214f9737-bd92-4392-8b1b-a75a81dacd6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고생', '사람', '끝', '낙', '사실', '고통', '시련', '어둠']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 내용 정리\n",
        "1. 문장으로 주로 어절이나 형태소 단위(단어)로 나누는 것을 \"토큰화\"라고 한다.\n",
        "\n",
        "2. 영어 토큰화는 nltk 라이브러리의 work_tokenize를 사용한다.\n",
        "\n",
        "3. 한글 토큰화는 konlpy 라이브러리의 OKT, KKMA를 사용한다."
      ],
      "metadata": {
        "id": "rZ_Hbp0geC4i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "voFQXYaSdxcf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}